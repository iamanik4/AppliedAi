{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "168QPRizVFFg"
   },
   "source": [
    "<p style=\"font-size:32px;text-align:center\"> <b>Social network Graph Link Prediction - Facebook Challenge</b> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8lS7fVyVFFl"
   },
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "# please do go through this python notebook: \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import csv\n",
    "import pandas as pd#pandas to create small dataframes \n",
    "import datetime #Convert to unix time\n",
    "import time #Convert to unix time\n",
    "# if numpy is not installed already : pip3 install numpy\n",
    "import numpy as np#Do aritmetic operations on arrays\n",
    "# matplotlib: used to plot graphs\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns#Plots\n",
    "from matplotlib import rcParams#Size of plots  \n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "# to install xgboost: pip3 install xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "import networkx as nx\n",
    "import pdb\n",
    "import pickle\n",
    "from pandas import HDFStore,DataFrame\n",
    "from pandas import read_hdf\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1znHayNeVFFt"
   },
   "source": [
    "# 1. Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uq9HbHwEVFFv",
    "outputId": "b2aa525a-93d3-47c3-8216-416a811bc812"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 1780722\n",
      "Number of edges: 7550015\n",
      "Average in degree:   4.2399\n",
      "Average out degree:   4.2399\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('train_pos_after_eda.csv'):\n",
    "    train_graph=nx.read_edgelist('train_pos_after_eda.csv',delimiter=',',create_using=nx.DiGraph(),nodetype=int)\n",
    "    print(nx.info(train_graph))\n",
    "else:\n",
    "    print(\"please run the FB_EDA.ipynb or download the files from drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HmlUa64tVFF7"
   },
   "source": [
    "# 2. Similarity measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ivVMUMiWVFF9"
   },
   "source": [
    "## 2.1 Jaccard Distance:\n",
    "http://www.statisticshowto.com/jaccard-index/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NoWCYuRBVFF_"
   },
   "source": [
    "\\begin{equation}\n",
    "j = \\frac{|X\\cap Y|}{|X \\cup Y|} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Seo4z5SnVFGB"
   },
   "outputs": [],
   "source": [
    "#for followees\n",
    "def jaccard_for_followees(a,b):\n",
    "    try:\n",
    "        if len(set(train_graph.successors(a))) == 0  | len(set(train_graph.successors(b))) == 0:\n",
    "            return 0\n",
    "        sim = (len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b)))))/\\\n",
    "                                    (len(set(train_graph.successors(a)).union(set(train_graph.successors(b)))))\n",
    "    except:\n",
    "        return 0\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oa9FMlS8VFGF",
    "outputId": "426a6833-1631-4024-c24a-d21ae7686472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#one test case\n",
    "print(jaccard_for_followees(273084,1505602))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gf8njOv6VFGK",
    "outputId": "8ba07727-a0ab-498e-819f-0d310876191c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#node 1635354 not in graph \n",
    "print(jaccard_for_followees(273084,1505602))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LO-a5ZkKVFGO"
   },
   "outputs": [],
   "source": [
    "#for followers\n",
    "def jaccard_for_followers(a,b):\n",
    "    try:\n",
    "        if len(set(train_graph.predecessors(a))) == 0  | len(set(g.predecessors(b))) == 0:\n",
    "            return 0\n",
    "        sim = (len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b)))))/\\\n",
    "                                 (len(set(train_graph.predecessors(a)).union(set(train_graph.predecessors(b)))))\n",
    "        return sim\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DlbX2t0jVFGQ",
    "outputId": "7e4b4536-442a-4b0c-ae02-fb442c1955db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(jaccard_for_followers(273084,470294))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OgeBW2LMVFGU",
    "outputId": "1e12fabe-d990-4506-bb6b-c86b01d1b0af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#node 1635354 not in graph \n",
    "print(jaccard_for_followees(669354,1635354))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MnH2my2UVFGX"
   },
   "source": [
    "## 2.2 Cosine distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XNvdBGS2VFGY"
   },
   "source": [
    "\\begin{equation}\n",
    "CosineDistance = \\frac{|X\\cap Y|}{|X|\\cdot|Y|} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iznz67EdVFGZ"
   },
   "outputs": [],
   "source": [
    "#for followees\n",
    "def cosine_for_followees(a,b):\n",
    "    try:\n",
    "        if len(set(train_graph.successors(a))) == 0  | len(set(train_graph.successors(b))) == 0:\n",
    "            return 0\n",
    "        sim = (len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b)))))/\\\n",
    "                                    (math.sqrt(len(set(train_graph.successors(a)))*len((set(train_graph.successors(b))))))\n",
    "        return sim\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H55ALjkMVFGc",
    "outputId": "531fceba-60f4-4e6b-97f4-f37733dc468f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(cosine_for_followees(273084,1505602))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q0RGKgJFVFGf",
    "outputId": "41202fc6-f4aa-4a1d-d8f6-84f960a3fbba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(cosine_for_followees(273084,1635354))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJ_yGxA0VFGj"
   },
   "outputs": [],
   "source": [
    "def cosine_for_followers(a,b):\n",
    "    try:\n",
    "        \n",
    "        if len(set(train_graph.predecessors(a))) == 0  | len(set(train_graph.predecessors(b))) == 0:\n",
    "            return 0\n",
    "        sim = (len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b)))))/\\\n",
    "                                     (math.sqrt(len(set(train_graph.predecessors(a))))*(len(set(train_graph.predecessors(b)))))\n",
    "        return sim\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "75QrFJb6VFGm",
    "outputId": "f01e0558-f1e3-465f-ab14-0e4ca764f4aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02886751345948129\n"
     ]
    }
   ],
   "source": [
    "print(cosine_for_followers(2,470294))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ut4k_F0VFGq",
    "outputId": "8bc9607a-7262-43e2-9de8-f71d276762fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(cosine_for_followers(669354,1635354))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DaIHhWh6VFGv"
   },
   "source": [
    "## 3. Ranking Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6nfV1SprVFGx"
   },
   "source": [
    "https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html\n",
    "\n",
    "PageRank computes a ranking of the nodes in the graph G based on the structure of the incoming links.\n",
    "\n",
    "<img src='PageRanks-Example.jpg'/>\n",
    "\n",
    "Mathematical PageRanks for a simple network, expressed as percentages. (Google uses a logarithmic scale.) Page C has a higher PageRank than Page E, even though there are fewer links to C; the one link to C comes from an important page and hence is of high value. If web surfers who start on a random page have an 85% likelihood of choosing a random link from the page they are currently visiting, and a 15% likelihood of jumping to a page chosen at random from the entire web, they will reach Page E 8.1% of the time. <b>(The 15% likelihood of jumping to an arbitrary page corresponds to a damping factor of 85%.) Without damping, all web surfers would eventually end up on Pages A, B, or C, and all other pages would have PageRank zero. In the presence of damping, Page A effectively links to all pages in the web, even though it has no outgoing links of its own.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GkkfYYZ6VFGy"
   },
   "source": [
    "## 3.1 Page Ranking\n",
    "\n",
    "https://en.wikipedia.org/wiki/PageRank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AtvqwZ34VFGy"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('page_rank.p'):\n",
    "    pr = nx.pagerank(train_graph, alpha=0.85)\n",
    "    pickle.dump(pr,open('page_rank.p','wb'))\n",
    "else:\n",
    "    pr = pickle.load(open('page_rank.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lXGKYYf6VFG2",
    "outputId": "bb3d1b7a-81f9-44ab-dbe7-3214ccd47179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 1.6556497245737814e-07\n",
      "max 2.7098251341935827e-05\n",
      "mean 5.615699699389075e-07\n"
     ]
    }
   ],
   "source": [
    "print('min',pr[min(pr, key=pr.get)])\n",
    "print('max',pr[max(pr, key=pr.get)])\n",
    "print('mean',float(sum(pr.values())) / len(pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5xwlah4oVFG4",
    "outputId": "992fdfad-7ff6-4626-c9ee-d9bce220a680"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.615699699389075e-07\n"
     ]
    }
   ],
   "source": [
    "#for imputing to nodes which are not there in Train data\n",
    "mean_pr = float(sum(pr.values())) / len(pr)\n",
    "print(mean_pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HhPbSL1tVFG7"
   },
   "source": [
    "# 4. Other Graph Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AgsorCl7VFG8"
   },
   "source": [
    "## 4.1 Shortest path:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7teH2LCVFG9"
   },
   "source": [
    "Getting Shortest path between twoo nodes, if nodes have direct path i.e directly connected then we are removing that edge and calculating path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RA076ovzVFG9"
   },
   "outputs": [],
   "source": [
    "#if has direct edge then deleting that edge and calculating shortest path\n",
    "def compute_shortest_path_length(a,b):\n",
    "    p=-1\n",
    "    try:\n",
    "        if train_graph.has_edge(a,b):\n",
    "            train_graph.remove_edge(a,b)\n",
    "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
    "            train_graph.add_edge(a,b)\n",
    "        else:\n",
    "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
    "        return p\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AxnKId11VFG_",
    "outputId": "15ca223a-6a04-4549-d010-54619b472a9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing\n",
    "compute_shortest_path_length(77697, 826021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0huWCNtRVFHC",
    "outputId": "6debfa4f-2067-48bc-84b3-ab86e2d9dea6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing\n",
    "compute_shortest_path_length(669354,1635354)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "baE_95bzVFHF"
   },
   "source": [
    "## 4.2 Checking for same community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "15CIQqAbVFHG"
   },
   "outputs": [],
   "source": [
    "#getting weekly connected edges from graph \n",
    "wcc=list(nx.weakly_connected_components(train_graph))\n",
    "def belongs_to_same_wcc(a,b):\n",
    "    index = []\n",
    "    if train_graph.has_edge(b,a):\n",
    "        return 1\n",
    "    if train_graph.has_edge(a,b):\n",
    "            for i in wcc:\n",
    "                if a in i:\n",
    "                    index= i\n",
    "                    break\n",
    "            if (b in index):\n",
    "                train_graph.remove_edge(a,b)\n",
    "                if compute_shortest_path_length(a,b)==-1:\n",
    "                    train_graph.add_edge(a,b)\n",
    "                    return 0\n",
    "                else:\n",
    "                    train_graph.add_edge(a,b)\n",
    "                    return 1\n",
    "            else:\n",
    "                return 0\n",
    "    else:\n",
    "            for i in wcc:\n",
    "                if a in i:\n",
    "                    index= i\n",
    "                    break\n",
    "            if(b in index):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fAzOHtCFVFHI",
    "outputId": "2b043a87-b460-42bf-f37e-4c04bbed6586"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "belongs_to_same_wcc(861, 1659750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HMdYpPuGVFHK",
    "outputId": "2005e22c-b60f-48d7-839b-650bf97cae35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "belongs_to_same_wcc(669354,1635354)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q74nth0OVFHN"
   },
   "source": [
    "## 4.3 Adamic/Adar Index:\n",
    "Adamic/Adar measures is defined as inverted sum of degrees of common neighbours for given two vertices.\n",
    "$$A(x,y)=\\sum_{u \\in N(x) \\cap N(y)}\\frac{1}{log(|N(u)|)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CeS98LI5VFHO"
   },
   "outputs": [],
   "source": [
    "#adar index\n",
    "def calc_adar_in(a,b):\n",
    "    sum=0\n",
    "    try:\n",
    "        n=list(set(train_graph.successors(a)).intersection(set(train_graph.successors(b))))\n",
    "        if len(n)!=0:\n",
    "            for i in n:\n",
    "                sum=sum+(1/np.log10(len(list(train_graph.predecessors(i)))))\n",
    "            return sum\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KezFeRmyVFHQ",
    "outputId": "2f9c0e11-02d9-4f28-d67a-65e3d4943e99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_adar_in(1,189226)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vj_m89bBVFHV",
    "outputId": "68a0a099-2954-402f-c80f-6d436ffa1aba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_adar_in(669354,1635354)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBUudhFAVFHY"
   },
   "source": [
    "## 4.4 Is persion was following back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_mwmopLVFHZ"
   },
   "outputs": [],
   "source": [
    "def follows_back(a,b):\n",
    "    if train_graph.has_edge(b,a):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LdjUXIfbVFHb",
    "outputId": "ed3d8640-9834-4a95-e712-804292da70e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "follows_back(1,189226)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PmZtL65YVFHf",
    "outputId": "18ea6fe2-3f96-42c0-d116-ecb76ddba4b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "follows_back(669354,1635354)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29Vrq2EXVFHi"
   },
   "source": [
    "## 4.5 Katz Centrality:\n",
    "https://en.wikipedia.org/wiki/Katz_centrality\n",
    "\n",
    "https://www.geeksforgeeks.org/katz-centrality-centrality-measure/\n",
    " Katz centrality computes the centrality for a node \n",
    "    based on the centrality of its neighbors. It is a \n",
    "    generalization of the eigenvector centrality. The\n",
    "    Katz centrality for node `i` is\n",
    " \n",
    "$$x_i = \\alpha \\sum_{j} A_{ij} x_j + \\beta,$$\n",
    "where `A` is the adjacency matrix of the graph G \n",
    "with eigenvalues $$\\lambda$$.\n",
    "\n",
    "The parameter $$\\beta$$ controls the initial centrality and \n",
    "\n",
    "$$\\alpha < \\frac{1}{\\lambda_{max}}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CN5OSqrkVFHj"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('katz.p'):\n",
    "    katz = nx.katz.katz_centrality(train_graph,alpha=0.005,beta=1)\n",
    "    pickle.dump(katz,open('katz.p','wb'))\n",
    "else:\n",
    "    katz = pickle.load(open('katz.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gcU83vw7VFHm",
    "outputId": "05f49ad4-46fe-4cf6-f32a-2fe4846b0714"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 0.0007313532484065916\n",
      "max 0.003394554981699122\n",
      "mean 0.0007483800935562018\n"
     ]
    }
   ],
   "source": [
    "print('min',katz[min(katz, key=katz.get)])\n",
    "print('max',katz[max(katz, key=katz.get)])\n",
    "print('mean',float(sum(katz.values())) / len(katz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qcboIksiVFHt",
    "outputId": "99f52422-9edb-479a-d5d9-e33401160da7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007483800935562018\n"
     ]
    }
   ],
   "source": [
    "mean_katz = float(sum(katz.values())) / len(katz)\n",
    "print(mean_katz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SRZqGFgYVFHx"
   },
   "source": [
    "## 4.6 Hits Score\n",
    "The HITS algorithm computes two numbers for a node. Authorities estimates the node value based on the incoming links. Hubs estimates the node value based on outgoing links.\n",
    "\n",
    "https://en.wikipedia.org/wiki/HITS_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WXNHRdzUVFHz"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('hits.p'):\n",
    "    hits = nx.hits(train_graph, max_iter=100, tol=1e-08, nstart=None, normalized=True)\n",
    "    pickle.dump(hits,open('hits.p','wb'))\n",
    "else:\n",
    "    hits = pickle.load(open('hits.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PSUwSZBVVFH3",
    "outputId": "77448253-5409-4229-f0be-b8dbc14d7f46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 0.0\n",
      "max 0.004868653378780953\n",
      "mean 5.615699699344123e-07\n"
     ]
    }
   ],
   "source": [
    "print('min',hits[0][min(hits[0], key=hits[0].get)])\n",
    "print('max',hits[0][max(hits[0], key=hits[0].get)])\n",
    "print('mean',float(sum(hits[0].values())) / len(hits[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Preferential Attachment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preferential attachment algorithm works on the idea that a user having more friends tends to create more new connections.\n",
    "we estimate how rich two vertices by calculating the multiplicating between number of followers each vertex has.\n",
    "\n",
    "\n",
    "                                         Score(x,y) = |Γ(x)|.|Γ(y)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predz_for_followees(a,b):\n",
    "    try:\n",
    "        if len(set(train_graph.successors(a))) == 0  | len(set(train_graph.successors(b))) == 0:\n",
    "            return 0\n",
    "        predz = len(set(train_graph.successors(a)))*len(set(train_graph.successors(b)))\n",
    "    except:\n",
    "        return 0\n",
    "    return predz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predz_for_followers(a,b):\n",
    "    try:\n",
    "        if len(set(train_graph.predecessors(a))) == 0  | len(set(train_graph.predecessors(b))) == 0:\n",
    "            return 0\n",
    "        predz = len(set(train_graph.predecessors(a)))*len(set(train_graph.predecessors(b)))\n",
    "    except:\n",
    "        return 0\n",
    "    return predz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZZtowOLZVFH6"
   },
   "source": [
    "# 5. Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o6NnRWmLVFH6"
   },
   "source": [
    "## 5. 1 Reading a sample of Data from both train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wgHje1UVVFH8"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "if os.path.isfile('train_after_eda.csv'):\n",
    "    filename = \"train_after_eda.csv\"\n",
    "    # you uncomment this line, if you dont know the lentgh of the file name\n",
    "    # here we have hardcoded the number of lines as 15100030\n",
    "    # n_train = sum(1 for line in open(filename)) #number of records in file (excludes header)\n",
    "    n_train =  15100028\n",
    "    s = 100000 #desired sample size\n",
    "    skip_train = sorted(random.sample(range(1,n_train+1),n_train-s))\n",
    "    #https://stackoverflow.com/a/22259008/4084039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOzuRFFlVFH-"
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('train_after_eda.csv'):\n",
    "    filename = \"test_after_eda.csv\"\n",
    "    # you uncomment this line, if you dont know the lentgh of the file name\n",
    "    # here we have hardcoded the number of lines as 3775008\n",
    "    # n_test = sum(1 for line in open(filename)) #number of records in file (excludes header)\n",
    "    n_test = 3775006\n",
    "    s = 50000 #desired sample size\n",
    "    skip_test = sorted(random.sample(range(1,n_test+1),n_test-s))\n",
    "    #https://stackoverflow.com/a/22259008/4084039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3D_SeUCOVFH_",
    "outputId": "322902a4-0420-4b99-8606-5fd0de4bbea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the train data file: 15100028\n",
      "Number of rows we are going to elimiate in train data are 15000028\n",
      "Number of rows in the test data file: 3775006\n",
      "Number of rows we are going to elimiate in test data are 3725006\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows in the train data file:\", n_train)\n",
    "print(\"Number of rows we are going to elimiate in train data are\",len(skip_train))\n",
    "print(\"Number of rows in the test data file:\", n_test)\n",
    "print(\"Number of rows we are going to elimiate in test data are\",len(skip_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCisf6PpVFID",
    "outputId": "daf2af43-3f98-4466-ad99-03bc54464714"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our train matrix size  (100002, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_node</th>\n",
       "      <th>destination_node</th>\n",
       "      <th>indicator_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273084</td>\n",
       "      <td>1505602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>832016</td>\n",
       "      <td>1543415</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_node  destination_node  indicator_link\n",
       "0       273084           1505602               1\n",
       "1       832016           1543415               1"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_train = pd.read_csv('train_after_eda.csv', skiprows=skip_train, names=['source_node', 'destination_node'])\n",
    "df_final_train['indicator_link'] = pd.read_csv('train_y.csv', skiprows=skip_train, names=['indicator_link'])\n",
    "print(\"Our train matrix size \",df_final_train.shape)\n",
    "df_final_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFn1RkdyVFIH",
    "outputId": "1ca99e70-6d2a-45f2-f51c-fd3b1211ad20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our test matrix size  (50002, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_node</th>\n",
       "      <th>destination_node</th>\n",
       "      <th>indicator_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>848424</td>\n",
       "      <td>784690</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>483294</td>\n",
       "      <td>1255532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_node  destination_node  indicator_link\n",
       "0       848424            784690               1\n",
       "1       483294           1255532               1"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_test = pd.read_csv('test_after_eda.csv', skiprows=skip_test, names=['source_node', 'destination_node'])\n",
    "df_final_test['indicator_link'] = pd.read_csv('test_y.csv', skiprows=skip_test, names=['indicator_link'])\n",
    "print(\"Our test matrix size \",df_final_test.shape)\n",
    "df_final_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gIaOWDaDVFIJ"
   },
   "source": [
    "## 5.2 Adding a set of features\n",
    "\n",
    "__we will create these each of these features for both train and test data points__\n",
    "<ol>\n",
    "<li>jaccard_followers</li>\n",
    "<li>jaccard_followees</li>\n",
    "<li>cosine_followers</li>\n",
    "<li>cosine_followees</li>\n",
    "<li>num_followers_s</li>\n",
    "<li>num_followees_s</li>\n",
    "<li>num_followers_d</li>\n",
    "<li>num_followees_d</li>\n",
    "<li>inter_followers</li>\n",
    "<li>inter_followees</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2qTkOiBcVFIJ"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('storage_sample_stage1.h5'):\n",
    "    #mapping jaccrd followers to train and test data\n",
    "    df_final_train['jaccard_followers'] = df_final_train.apply(lambda row:\n",
    "                                            jaccard_for_followers(row['source_node'],row['destination_node']),axis=1)\n",
    "    df_final_test['jaccard_followers'] = df_final_test.apply(lambda row:\n",
    "                                            jaccard_for_followers(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    #mapping jaccrd followees to train and test data\n",
    "    df_final_train['jaccard_followees'] = df_final_train.apply(lambda row:\n",
    "                                            jaccard_for_followees(row['source_node'],row['destination_node']),axis=1)\n",
    "    df_final_test['jaccard_followees'] = df_final_test.apply(lambda row:\n",
    "                                            jaccard_for_followees(row['source_node'],row['destination_node']),axis=1)\n",
    "    \n",
    "\n",
    "        #mapping jaccrd followers to train and test data\n",
    "    df_final_train['cosine_followers'] = df_final_train.apply(lambda row:\n",
    "                                            cosine_for_followers(row['source_node'],row['destination_node']),axis=1)\n",
    "    df_final_test['cosine_followers'] = df_final_test.apply(lambda row:\n",
    "                                            cosine_for_followers(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    #mapping jaccrd followees to train and test data\n",
    "    df_final_train['cosine_followees'] = df_final_train.apply(lambda row:\n",
    "                                            cosine_for_followees(row['source_node'],row['destination_node']),axis=1)\n",
    "    df_final_test['cosine_followees'] = df_final_test.apply(lambda row:\n",
    "                                            cosine_for_followees(row['source_node'],row['destination_node']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fz2eZpSnVFIL"
   },
   "outputs": [],
   "source": [
    "def compute_features_stage1(df_final):\n",
    "    #calculating no of followers followees for source and destination\n",
    "    #calculating intersection of followers and followees for source and destination\n",
    "    num_followers_s=[]\n",
    "    num_followees_s=[]\n",
    "    num_followers_d=[]\n",
    "    num_followees_d=[]\n",
    "    inter_followers=[]\n",
    "    inter_followees=[]\n",
    "    for i,row in df_final.iterrows():\n",
    "        try:\n",
    "            s1=set(train_graph.predecessors(row['source_node']))\n",
    "            s2=set(train_graph.successors(row['source_node']))\n",
    "        except:\n",
    "            s1 = set()\n",
    "            s2 = set()\n",
    "        try:\n",
    "            d1=set(train_graph.predecessors(row['destination_node']))\n",
    "            d2=set(train_graph.successors(row['destination_node']))\n",
    "        except:\n",
    "            d1 = set()\n",
    "            d2 = set()\n",
    "        num_followers_s.append(len(s1))\n",
    "        num_followees_s.append(len(s2))\n",
    "\n",
    "        num_followers_d.append(len(d1))\n",
    "        num_followees_d.append(len(d2))\n",
    "\n",
    "        inter_followers.append(len(s1.intersection(d1)))\n",
    "        inter_followees.append(len(s2.intersection(d2)))\n",
    "    \n",
    "    return num_followers_s, num_followers_d, num_followees_s, num_followees_d, inter_followers, inter_followees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VFc60kcRVFIN"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('storage_sample_stage1.h5'):\n",
    "    df_final_train['num_followers_s'], df_final_train['num_followers_d'], \\\n",
    "    df_final_train['num_followees_s'], df_final_train['num_followees_d'], \\\n",
    "    df_final_train['inter_followers'], df_final_train['inter_followees']= compute_features_stage1(df_final_train)\n",
    "    \n",
    "    df_final_test['num_followers_s'], df_final_test['num_followers_d'], \\\n",
    "    df_final_test['num_followees_s'], df_final_test['num_followees_d'], \\\n",
    "    df_final_test['inter_followers'], df_final_test['inter_followees']= compute_features_stage1(df_final_test)\n",
    "    \n",
    "    hdf = HDFStore('storage_sample_stage1.h5')\n",
    "    hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
    "    hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
    "    hdf.close()\n",
    "else:\n",
    "    df_final_train = read_hdf('storage_sample_stage1.h5', 'train_df',mode='r')\n",
    "    df_final_test = read_hdf('storage_sample_stage1.h5', 'test_df',mode='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "go_e8hxxVFIO"
   },
   "source": [
    "## 5.3 Adding new set of features\n",
    "\n",
    "__we will create these each of these features for both train and test data points__\n",
    "<ol>\n",
    "<li>adar index</li>\n",
    "<li>is following back</li>\n",
    "<li>belongs to same weakly connect components</li>\n",
    "<li>shortest path between source and destination</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LqB0Peg0VFIP"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('storage_sample_stage2.h5'):\n",
    "    #mapping adar index on train\n",
    "    df_final_train['adar_index'] = df_final_train.apply(lambda row: calc_adar_in(row['source_node'],row['destination_node']),axis=1)\n",
    "    #mapping adar index on test\n",
    "    df_final_test['adar_index'] = df_final_test.apply(lambda row: calc_adar_in(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------\n",
    "    #mapping followback or not on train\n",
    "    df_final_train['follows_back'] = df_final_train.apply(lambda row: follows_back(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    #mapping followback or not on test\n",
    "    df_final_test['follows_back'] = df_final_test.apply(lambda row: follows_back(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------------\n",
    "    #mapping same component of wcc or not on train\n",
    "    df_final_train['same_comp'] = df_final_train.apply(lambda row: belongs_to_same_wcc(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    ##mapping same component of wcc or not on train\n",
    "    df_final_test['same_comp'] = df_final_test.apply(lambda row: belongs_to_same_wcc(row['source_node'],row['destination_node']),axis=1)\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------------\n",
    "    #mapping shortest path on train \n",
    "    df_final_train['shortest_path'] = df_final_train.apply(lambda row: compute_shortest_path_length(row['source_node'],row['destination_node']),axis=1)\n",
    "    #mapping shortest path on test\n",
    "    df_final_test['shortest_path'] = df_final_test.apply(lambda row: compute_shortest_path_length(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    hdf = HDFStore('storage_sample_stage2.h5')\n",
    "    hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
    "    hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
    "    hdf.close()\n",
    "else:\n",
    "    df_final_train = read_hdf('storage_sample_stage2.h5', 'train_df',mode='r')\n",
    "    df_final_test = read_hdf('storage_sample_stage2.h5', 'test_df',mode='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HJ8Dbma_VFIR"
   },
   "source": [
    "## 5.4 Adding new set of features\n",
    "\n",
    "__we will create these each of these features for both train and test data points__\n",
    "<ol>\n",
    "<li>Weight Features\n",
    "    <ul>\n",
    "        <li>weight of incoming edges</li>\n",
    "        <li>weight of outgoing edges</li>\n",
    "        <li>weight of incoming edges + weight of outgoing edges</li>\n",
    "        <li>weight of incoming edges * weight of outgoing edges</li>\n",
    "        <li>2*weight of incoming edges + weight of outgoing edges</li>\n",
    "        <li>weight of incoming edges + 2*weight of outgoing edges</li>\n",
    "    </ul>\n",
    "</li>\n",
    "<li>Page Ranking of source</li>\n",
    "<li>Page Ranking of dest</li>\n",
    "<li>katz of source</li>\n",
    "<li>katz of dest</li>\n",
    "<li>hubs of source</li>\n",
    "<li>hubs of dest</li>\n",
    "<li>authorities_s of source</li>\n",
    "<li>authorities_s of dest</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iVHI2jtNVFIS"
   },
   "source": [
    "#### Weight Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rXmUYF9FVFIT"
   },
   "source": [
    "In order to determine the similarity of nodes, an edge weight value was calculated between nodes. Edge weight decreases as the neighbor count goes up. Intuitively, consider one million people following a celebrity on a social network then chances are most of them never met each other or the celebrity. On the other hand, if a user has 30 contacts in his/her social network, the chances are higher that many of them know each other. \n",
    "`credit` - Graph-based Features for Supervised Link Prediction\n",
    "William Cukierski, Benjamin Hamner, Bo Yang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qzbs2no7VFIV"
   },
   "source": [
    "\\begin{equation}\n",
    "W = \\frac{1}{\\sqrt{1+|X|}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kkzUPrWaVFIV"
   },
   "source": [
    "it is directed graph so calculated Weighted in and Weighted out differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FgNMzzTbVFIW",
    "outputId": "7e8e6d88-8bd6-45f6-f80e-82b093c18974"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 1780722/1780722 [00:11<00:00, 152682.24it/s]\n"
     ]
    }
   ],
   "source": [
    "#weight for source and destination of each link\n",
    "Weight_in = {}\n",
    "Weight_out = {}\n",
    "for i in  tqdm(train_graph.nodes()):\n",
    "    s1=set(train_graph.predecessors(i))\n",
    "    w_in = 1.0/(np.sqrt(1+len(s1)))\n",
    "    Weight_in[i]=w_in\n",
    "    \n",
    "    s2=set(train_graph.successors(i))\n",
    "    w_out = 1.0/(np.sqrt(1+len(s2)))\n",
    "    Weight_out[i]=w_out\n",
    "    \n",
    "#for imputing with mean\n",
    "mean_weight_in = np.mean(list(Weight_in.values()))\n",
    "mean_weight_out = np.mean(list(Weight_out.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AF4yPhIOVFIY"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('storage_sample_stage3.h5'):\n",
    "    #mapping to pandas train\n",
    "    df_final_train['weight_in'] = df_final_train.destination_node.apply(lambda x: Weight_in.get(x,mean_weight_in))\n",
    "    df_final_train['weight_out'] = df_final_train.source_node.apply(lambda x: Weight_out.get(x,mean_weight_out))\n",
    "\n",
    "    #mapping to pandas test\n",
    "    df_final_test['weight_in'] = df_final_test.destination_node.apply(lambda x: Weight_in.get(x,mean_weight_in))\n",
    "    df_final_test['weight_out'] = df_final_test.source_node.apply(lambda x: Weight_out.get(x,mean_weight_out))\n",
    "\n",
    "\n",
    "    #some features engineerings on the in and out weights\n",
    "    df_final_train['weight_f1'] = df_final_train.weight_in + df_final_train.weight_out\n",
    "    df_final_train['weight_f2'] = df_final_train.weight_in * df_final_train.weight_out\n",
    "    df_final_train['weight_f3'] = (2*df_final_train.weight_in + 1*df_final_train.weight_out)\n",
    "    df_final_train['weight_f4'] = (1*df_final_train.weight_in + 2*df_final_train.weight_out)\n",
    "\n",
    "    #some features engineerings on the in and out weights\n",
    "    df_final_test['weight_f1'] = df_final_test.weight_in + df_final_test.weight_out\n",
    "    df_final_test['weight_f2'] = df_final_test.weight_in * df_final_test.weight_out\n",
    "    df_final_test['weight_f3'] = (2*df_final_test.weight_in + 1*df_final_test.weight_out)\n",
    "    df_final_test['weight_f4'] = (1*df_final_test.weight_in + 2*df_final_test.weight_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uhxzhQ9aVFIa"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('storage_sample_stage3.h5'):\n",
    "    \n",
    "    #page rank for source and destination in Train and Test\n",
    "    #if anything not there in train graph then adding mean page rank \n",
    "    df_final_train['page_rank_s'] = df_final_train.source_node.apply(lambda x:pr.get(x,mean_pr))\n",
    "    df_final_train['page_rank_d'] = df_final_train.destination_node.apply(lambda x:pr.get(x,mean_pr))\n",
    "\n",
    "    df_final_test['page_rank_s'] = df_final_test.source_node.apply(lambda x:pr.get(x,mean_pr))\n",
    "    df_final_test['page_rank_d'] = df_final_test.destination_node.apply(lambda x:pr.get(x,mean_pr))\n",
    "    #================================================================================\n",
    "\n",
    "    #Katz centrality score for source and destination in Train and test\n",
    "    #if anything not there in train graph then adding mean katz score\n",
    "    df_final_train['katz_s'] = df_final_train.source_node.apply(lambda x: katz.get(x,mean_katz))\n",
    "    df_final_train['katz_d'] = df_final_train.destination_node.apply(lambda x: katz.get(x,mean_katz))\n",
    "\n",
    "    df_final_test['katz_s'] = df_final_test.source_node.apply(lambda x: katz.get(x,mean_katz))\n",
    "    df_final_test['katz_d'] = df_final_test.destination_node.apply(lambda x: katz.get(x,mean_katz))\n",
    "    #================================================================================\n",
    "\n",
    "    #Hits algorithm score for source and destination in Train and test\n",
    "    #if anything not there in train graph then adding 0\n",
    "    df_final_train['hubs_s'] = df_final_train.source_node.apply(lambda x: hits[0].get(x,0))\n",
    "    df_final_train['hubs_d'] = df_final_train.destination_node.apply(lambda x: hits[0].get(x,0))\n",
    "\n",
    "    df_final_test['hubs_s'] = df_final_test.source_node.apply(lambda x: hits[0].get(x,0))\n",
    "    df_final_test['hubs_d'] = df_final_test.destination_node.apply(lambda x: hits[0].get(x,0))\n",
    "    #================================================================================\n",
    "\n",
    "    #Hits algorithm score for source and destination in Train and Test\n",
    "    #if anything not there in train graph then adding 0\n",
    "    df_final_train['authorities_s'] = df_final_train.source_node.apply(lambda x: hits[1].get(x,0))\n",
    "    df_final_train['authorities_d'] = df_final_train.destination_node.apply(lambda x: hits[1].get(x,0))\n",
    "\n",
    "    df_final_test['authorities_s'] = df_final_test.source_node.apply(lambda x: hits[1].get(x,0))\n",
    "    df_final_test['authorities_d'] = df_final_test.destination_node.apply(lambda x: hits[1].get(x,0))\n",
    "    #================================================================================\n",
    "\n",
    "    hdf = HDFStore('storage_sample_stage3.h5')\n",
    "    hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
    "    hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
    "    hdf.close()\n",
    "else:\n",
    "    df_final_train = read_hdf('storage_sample_stage3.h5', 'train_df',mode='r')\n",
    "    df_final_test = read_hdf('storage_sample_stage3.h5', 'test_df',mode='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p6xkDfD-VFIb"
   },
   "source": [
    "## 5.5 Adding new set of features\n",
    "\n",
    "__we will create these each of these features for both train and test data points__\n",
    "<ol>\n",
    "<li>SVD features for both source and destination</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WQO6E65eVFIc"
   },
   "outputs": [],
   "source": [
    "def svd(x, S):\n",
    "    try:\n",
    "        z = sadj_dict[x]\n",
    "        return S[z]\n",
    "    except:\n",
    "        return [0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9sOyLwvNVFId"
   },
   "outputs": [],
   "source": [
    "#for svd features to get feature vector creating a dict node val and index in svd vector\n",
    "sadj_col = sorted(train_graph.nodes())\n",
    "sadj_dict = { val:idx for idx,val in enumerate(sadj_col)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zLSt8fGVVFIg"
   },
   "outputs": [],
   "source": [
    "Adj = nx.adjacency_matrix(train_graph,nodelist=sorted(train_graph.nodes())).asfptype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "soq-VAHlVFIh",
    "outputId": "3f9bfb32-004f-4698-e415-469243250130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix Shape (1780722, 1780722)\n",
      "U Shape (1780722, 6)\n",
      "V Shape (6, 1780722)\n",
      "s Shape (6,)\n"
     ]
    }
   ],
   "source": [
    "U, s, V = svds(Adj, k = 6)\n",
    "print('Adjacency matrix Shape',Adj.shape)\n",
    "print('U Shape',U.shape)\n",
    "print('V Shape',V.shape)\n",
    "print('s Shape',s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ls5fqLFhVFIm"
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('storage_sample_stage4.h5'):\n",
    "    #===================================================================================================\n",
    "    \n",
    "    df_final_train[['svd_u_s_1', 'svd_u_s_2','svd_u_s_3', 'svd_u_s_4', 'svd_u_s_5', 'svd_u_s_6']] = \\\n",
    "    df_final_train.source_node.apply(lambda x: svd(x, U)).apply(pd.Series)\n",
    "    \n",
    "    df_final_train[['svd_u_d_1', 'svd_u_d_2', 'svd_u_d_3', 'svd_u_d_4', 'svd_u_d_5','svd_u_d_6']] = \\\n",
    "    df_final_train.destination_node.apply(lambda x: svd(x, U)).apply(pd.Series)\n",
    "    #===================================================================================================\n",
    "    \n",
    "    df_final_train[['svd_v_s_1','svd_v_s_2', 'svd_v_s_3', 'svd_v_s_4', 'svd_v_s_5', 'svd_v_s_6',]] = \\\n",
    "    df_final_train.source_node.apply(lambda x: svd(x, V.T)).apply(pd.Series)\n",
    "\n",
    "    df_final_train[['svd_v_d_1', 'svd_v_d_2', 'svd_v_d_3', 'svd_v_d_4', 'svd_v_d_5','svd_v_d_6']] = \\\n",
    "    df_final_train.destination_node.apply(lambda x: svd(x, V.T)).apply(pd.Series)\n",
    "    #===================================================================================================\n",
    "    \n",
    "    df_final_test[['svd_u_s_1', 'svd_u_s_2','svd_u_s_3', 'svd_u_s_4', 'svd_u_s_5', 'svd_u_s_6']] = \\\n",
    "    df_final_test.source_node.apply(lambda x: svd(x, U)).apply(pd.Series)\n",
    "    \n",
    "    df_final_test[['svd_u_d_1', 'svd_u_d_2', 'svd_u_d_3', 'svd_u_d_4', 'svd_u_d_5','svd_u_d_6']] = \\\n",
    "    df_final_test.destination_node.apply(lambda x: svd(x, U)).apply(pd.Series)\n",
    "\n",
    "    #===================================================================================================\n",
    "    \n",
    "    df_final_test[['svd_v_s_1','svd_v_s_2', 'svd_v_s_3', 'svd_v_s_4', 'svd_v_s_5', 'svd_v_s_6',]] = \\\n",
    "    df_final_test.source_node.apply(lambda x: svd(x, V.T)).apply(pd.Series)\n",
    "\n",
    "    df_final_test[['svd_v_d_1', 'svd_v_d_2', 'svd_v_d_3', 'svd_v_d_4', 'svd_v_d_5','svd_v_d_6']] = \\\n",
    "    df_final_test.destination_node.apply(lambda x: svd(x, V.T)).apply(pd.Series)\n",
    "    #===================================================================================================\n",
    "\n",
    "    hdf = HDFStore('storage_sample_stage4.h5')\n",
    "    hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
    "    hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
    "    hdf.close()\n",
    "else:\n",
    "    df_final_train = read_hdf('storage_sample_stage4.h5', 'train_df',mode='r')\n",
    "    df_final_test = read_hdf('storage_sample_stage4.h5', 'test_df',mode='r')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Adding new set of features\n",
    "\n",
    "we will create these each of these features for both train and test data points\n",
    "\n",
    "1. Preferential Attachment feature for both source and destination nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_train = read_hdf('storage_sample_stage4.h5', 'train_df',mode='r')\n",
    "df_final_test = read_hdf('storage_sample_stage4.h5', 'test_df',mode='r') \n",
    "if not os.path.isfile('storage_sample_stage5.h5'):\n",
    "    #mapping jaccrd followers to train and test data\n",
    "    df_final_train['predz_followers'] = df_final_train.apply(lambda row:\n",
    "                                            predz_for_followers(row['source_node'],row['destination_node']),axis=1)\n",
    "    df_final_test['predz_followers'] = df_final_test.apply(lambda row:\n",
    "                                            predz_for_followers(row['source_node'],row['destination_node']),axis=1)\n",
    "\n",
    "    #mapping jaccrd followees to train and test data\n",
    "    df_final_train['predz_followees'] = df_final_train.apply(lambda row:\n",
    "                                            predz_for_followees(row['source_node'],row['destination_node']),axis=1)\n",
    "    df_final_test['predz_followees'] = df_final_test.apply(lambda row:\n",
    "                                            predz_for_followees(row['source_node'],row['destination_node']),axis=1)\n",
    "    \n",
    "\n",
    "    #mapping svd_dot to train set\n",
    "    df_final_train['src_svc_dot'] = df_final_train[['svd_u_s_1', 'svd_u_d_1']].product(axis=1) \\\n",
    "                                  + df_final_train[['svd_u_s_2', 'svd_u_d_2']].product(axis=1) \\\n",
    "                                  + df_final_train[['svd_u_s_3', 'svd_u_d_3']].product(axis=1) \\\n",
    "                                  + df_final_train[['svd_u_s_4', 'svd_u_d_4']].product(axis=1) \\\n",
    "                                  + df_final_train[['svd_u_s_5', 'svd_u_d_5']].product(axis=1) \\\n",
    "                                  + df_final_train[['svd_u_s_6', 'svd_u_d_6']].product(axis=1) \n",
    "                        \n",
    "    df_final_train['des_svc_dot'] = df_final_train[['svd_v_s_1', 'svd_v_d_1']].product(axis=1) \\\n",
    "                                  + df_final_train[['svd_v_s_2', 'svd_u_d_2']].product(axis=1) \\\n",
    "                                  + df_final_train[['svd_v_s_3', 'svd_v_d_3']].product(axis=1) \\\n",
    "                                  + df_final_train[['svd_v_s_4', 'svd_v_d_4']].product(axis=1) \\\n",
    "                                  + df_final_train[['svd_v_s_5', 'svd_v_d_5']].product(axis=1) \\\n",
    "                                  + df_final_train[['svd_v_s_6', 'svd_v_d_6']].product(axis=1) \n",
    "    \n",
    "    #mapping svd_dot to test set\n",
    "    df_final_test['src_svc_dot'] = df_final_test[['svd_u_s_1', 'svd_u_d_1']].product(axis=1) \\\n",
    "                                 + df_final_test[['svd_u_s_2', 'svd_u_d_2']].product(axis=1) \\\n",
    "                                 + df_final_test[['svd_u_s_3', 'svd_u_d_3']].product(axis=1) \\\n",
    "                                 + df_final_test[['svd_u_s_4', 'svd_u_d_4']].product(axis=1) \\\n",
    "                                 + df_final_test[['svd_u_s_5', 'svd_u_d_5']].product(axis=1) \\\n",
    "                                 + df_final_test[['svd_u_s_6', 'svd_u_d_6']].product(axis=1) \n",
    "                        \n",
    "    df_final_test['des_svc_dot'] = df_final_test[['svd_v_s_1', 'svd_v_d_1']].product(axis=1) \\\n",
    "                                 + df_final_test[['svd_v_s_2', 'svd_u_d_2']].product(axis=1) \\\n",
    "                                 + df_final_test[['svd_v_s_3', 'svd_v_d_3']].product(axis=1) \\\n",
    "                                 + df_final_test[['svd_v_s_4', 'svd_v_d_4']].product(axis=1) \\\n",
    "                                 + df_final_test[['svd_v_s_5', 'svd_v_d_5']].product(axis=1) \\\n",
    "                                 + df_final_test[['svd_v_s_6', 'svd_v_d_6']].product(axis=1)                    \n",
    "    \n",
    "    hdf = HDFStore('storage_sample_stage5.h5')\n",
    "    hdf.put('train_df',df_final_train, format='table', data_columns=True)\n",
    "    hdf.put('test_df',df_final_test, format='table', data_columns=True)\n",
    "    hdf.close()\n",
    "else:\n",
    "    df_final_train = read_hdf('storage_sample_stage5.h5', 'train_df',mode='r')\n",
    "    df_final_test = read_hdf('storage_sample_stage5.h5', 'test_df',mode='r')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0-hBtlkzVFIn"
   },
   "outputs": [],
   "source": [
    "#reading\n",
    "from pandas import read_hdf\n",
    "df_final_train = read_hdf('storage_sample_stage5.h5', 'train_df',mode='r')\n",
    "df_final_test = read_hdf('storage_sample_stage5.h5', 'test_df',mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source_node', 'destination_node', 'indicator_link',\n",
       "       'jaccard_followers', 'jaccard_followees', 'cosine_followers',\n",
       "       'cosine_followees', 'num_followers_s', 'num_followees_s',\n",
       "       'num_followees_d', 'inter_followers', 'inter_followees', 'adar_index',\n",
       "       'follows_back', 'same_comp', 'shortest_path', 'weight_in', 'weight_out',\n",
       "       'weight_f1', 'weight_f2', 'weight_f3', 'weight_f4', 'page_rank_s',\n",
       "       'page_rank_d', 'katz_s', 'katz_d', 'hubs_s', 'hubs_d', 'authorities_s',\n",
       "       'authorities_d', 'svd_u_s_1', 'svd_u_s_2', 'svd_u_s_3', 'svd_u_s_4',\n",
       "       'svd_u_s_5', 'svd_u_s_6', 'svd_u_d_1', 'svd_u_d_2', 'svd_u_d_3',\n",
       "       'svd_u_d_4', 'svd_u_d_5', 'svd_u_d_6', 'svd_v_s_1', 'svd_v_s_2',\n",
       "       'svd_v_s_3', 'svd_v_s_4', 'svd_v_s_5', 'svd_v_s_6', 'svd_v_d_1',\n",
       "       'svd_v_d_2', 'svd_v_d_3', 'svd_v_d_4', 'svd_v_d_5', 'svd_v_d_6',\n",
       "       'predz_followers', 'predz_followees', 'src_svc_dot', 'des_svc_dot'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_final_train.indicator_link\n",
    "y_test = df_final_test.indicator_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_train.drop(['source_node', 'destination_node','indicator_link'],axis=1,inplace=True)\n",
    "df_final_test.drop(['source_node', 'destination_node','indicator_link'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Hyperparameter tunning for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Lalit Jain\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\", line 181, in __call__\n    y_pred = clf.decision_function(X)\nAttributeError: 'XGBClassifier' object has no attribute 'decision_function'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Lalit Jain\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\Lalit Jain\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\Lalit Jain\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Lalit Jain\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\Lalit Jain\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\Lalit Jain\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 558, in _fit_and_score\n    is_multimetric)\n  File \"C:\\Users\\Lalit Jain\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 597, in _score\n    return _multimetric_score(estimator, X_test, y_test, scorer)\n  File \"C:\\Users\\Lalit Jain\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 627, in _multimetric_score\n    score = scorer(estimator, X_test, y_test)\n  File \"C:\\Users\\Lalit Jain\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\", line 188, in __call__\n    y_pred = clf.predict_proba(X)\n  File \"C:\\Users\\Lalit Jain\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 829, in predict_proba\n    test_dmatrix = DMatrix(data, missing=self.missing, nthread=self.n_jobs)\n  File \"C:\\Users\\Lalit Jain\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 380, in __init__\n    feature_types)\n  File \"C:\\Users\\Lalit Jain\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 253, in _maybe_pandas_data\n    data = data.values.astype('float')\nMemoryError\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-aa90bab2de23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_final_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    685\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    664\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 666\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parameters = {'n_estimators': [5, 10,50, 100,200, 500]}\n",
    "clf = GridSearchCV(xgb.XGBClassifier(), parameters, cv=5, scoring='roc_auc',return_train_score=True,n_jobs=-1)\n",
    "clf.fit(df_final_train, y_train)\n",
    "\n",
    "results = pd.DataFrame.from_dict(clf.cv_results_)\n",
    "results = results.sort_values(['param_n_estimators'])\n",
    "\n",
    "train_auc= results['mean_train_score']\n",
    "cv_auc = results['mean_test_score'] \n",
    "sample_split =  results['param_n_estimators']\n",
    "\n",
    "plt.plot(sample_split, train_auc, label='Train AUC')\n",
    "# this code is copied from here: https://stackoverflow.com/a/48803361/4084039\n",
    "# plt.gca().fill_between(K, train_auc - train_auc_std,train_auc + train_auc_std,alpha=0.2,color='darkblue')\n",
    "\n",
    "plt.plot(sample_split, cv_auc, label='CV AUC')\n",
    "# this code is copied from here: https://stackoverflow.com/a/48803361/4084039\n",
    "# plt.gca().fill_between(K, cv_auc - cv_auc_std,cv_auc + cv_auc_std,alpha=0.2,color='darkorange')\n",
    "\n",
    "plt.scatter(sample_split, train_auc, label='Train AUC points')\n",
    "plt.scatter(sample_split, cv_auc, label='CV AUC points')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"sample_split: hyperparameter\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.title(\"Hyper parameter Vs Auccracy_Score plot\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best cross-validation score: {:.2f}\".format(clf.best_score_))\n",
    "print(\"Best parameters: \", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "DaIHhWh6VFGv",
    "GkkfYYZ6VFGy",
    "AgsorCl7VFG8",
    "baE_95bzVFHF",
    "pBUudhFAVFHY",
    "29Vrq2EXVFHi",
    "SRZqGFgYVFHx"
   ],
   "name": "FB_featurization.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
